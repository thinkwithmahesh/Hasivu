# HASIVU Platform - Performance Testing Workflow
# Priority 3 Enhancement: Automated performance validation pipeline
# Runs comprehensive performance tests on PR and deployment events

name: Performance Testing & Quality Gates

on:
  pull_request:
    branches: [main, develop]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - '.gitignore'

  push:
    branches: [main, develop]

  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'

  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment for testing'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production
      test_type:
        description: 'Type of performance tests to run'
        required: true
        default: 'full'
        type: choice
        options:
          - smoke
          - e2e
          - load
          - chaos
          - full
      enable_chaos:
        description: 'Enable chaos engineering tests'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18.19.0'
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'

jobs:
  # Job 1: Environment Setup & Validation
  setup-and-validate:
    name: Setup & Environment Validation
    runs-on: ubuntu-latest

    outputs:
      test-environment: ${{ steps.determine-env.outputs.environment }}
      test-type: ${{ steps.determine-type.outputs.type }}
      cache-key: ${{ steps.cache-keys.outputs.key }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Determine test environment
        id: determine-env
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
            echo "environment=development" >> $GITHUB_OUTPUT
          else
            echo "environment=development" >> $GITHUB_OUTPUT
          fi

      - name: Determine test type
        id: determine-type
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "type=${{ github.event.inputs.test_type }}" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            echo "type=smoke" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "type=full" >> $GITHUB_OUTPUT
          else
            echo "type=e2e" >> $GITHUB_OUTPUT
          fi

      - name: Generate cache keys
        id: cache-keys
        run: |
          echo "key=performance-deps-${{ runner.os }}-${{ hashFiles('**/package-lock.json') }}" >> $GITHUB_OUTPUT

      - name: Install dependencies
        run: |
          npm ci --prefer-offline --no-audit
          npm run build

      - name: Validate configuration
        run: |
          echo "Test Environment: ${{ steps.determine-env.outputs.environment }}"
          echo "Test Type: ${{ steps.determine-type.outputs.type }}"
          echo "Enable Chaos: ${{ github.event.inputs.enable_chaos || 'false' }}"

          # Validate required environment variables exist
          if [[ "${{ steps.determine-env.outputs.environment }}" == "staging" ]]; then
            if [[ -z "${{ secrets.STAGING_API_URL }}" ]]; then
              echo "::error::STAGING_API_URL secret not configured"
              exit 1
            fi
          fi

      - name: Cache dependencies and build
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            dist
            ~/.npm
          key: ${{ steps.cache-keys.outputs.key }}
          restore-keys: |
            performance-deps-${{ runner.os }}-

  # Job 2: Smoke Tests (Always run on PRs)
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    needs: setup-and-validate
    if: needs.setup-and-validate.outputs.test-type == 'smoke' || needs.setup-and-validate.outputs.test-type == 'full'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore dependencies
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            dist
            ~/.npm
          key: ${{ needs.setup-and-validate.outputs.cache-key }}

      - name: Run smoke tests
        env:
          TEST_ENVIRONMENT: ${{ needs.setup-and-validate.outputs.test-environment }}
          TEST_TYPE: smoke
          DEV_API_URL: ${{ secrets.DEV_API_URL }}
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
          PROD_API_URL: ${{ secrets.PROD_API_URL }}
        run: |
          npm run test:smoke:${{ needs.setup-and-validate.outputs.test-environment }}

      - name: Upload smoke test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: smoke-test-results-${{ needs.setup-and-validate.outputs.test-environment }}
          path: test-reports/
          retention-days: 30

  # Job 3: End-to-End Integration Tests
  e2e-tests:
    name: E2E Integration Tests
    runs-on: ubuntu-latest
    needs: [setup-and-validate, smoke-tests]
    if: |
      always() && 
      needs.smoke-tests.result == 'success' &&
      (needs.setup-and-validate.outputs.test-type == 'e2e' || needs.setup-and-validate.outputs.test-type == 'full')

    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: testpassword
          POSTGRES_USER: testuser
          POSTGRES_DB: hasivu_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore dependencies
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            dist
            ~/.npm
          key: ${{ needs.setup-and-validate.outputs.cache-key }}

      - name: Setup test database
        env:
          DATABASE_URL: postgres://testuser:testpassword@localhost:5432/hasivu_test
        run: |
          npm run db:generate
          npm run db:migrate
          npm run db:seed

      - name: Run E2E tests
        env:
          TEST_ENVIRONMENT: ${{ needs.setup-and-validate.outputs.test-environment }}
          TEST_TYPE: e2e
          DATABASE_URL: postgres://testuser:testpassword@localhost:5432/hasivu_test
          REDIS_URL: redis://localhost:6379
          DEV_API_URL: ${{ secrets.DEV_API_URL }}
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
          PROD_API_URL: ${{ secrets.PROD_API_URL }}
        run: |
          npm run test:e2e:comprehensive

      - name: Generate E2E test report
        if: always()
        run: |
          echo "E2E Tests completed for ${{ needs.setup-and-validate.outputs.test-environment }}" > test-summary.txt
          if [ -f "test-reports/${{ needs.setup-and-validate.outputs.test-environment }}/test-report-*.json" ]; then
            echo "Test report generated successfully" >> test-summary.txt
          else
            echo "Warning: Test report not found" >> test-summary.txt
          fi

      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results-${{ needs.setup-and-validate.outputs.test-environment }}
          path: |
            test-reports/
            test-summary.txt
          retention-days: 30

  # Job 4: Load & Performance Tests
  load-tests:
    name: Load & Performance Tests
    runs-on: ubuntu-latest
    needs: [setup-and-validate, e2e-tests]
    if: |
      always() && 
      needs.e2e-tests.result == 'success' &&
      (needs.setup-and-validate.outputs.test-type == 'load' || needs.setup-and-validate.outputs.test-type == 'full')

    strategy:
      matrix:
        load-profile:
          - name: 'light'
            concurrent: 10
            duration: 60
          - name: 'moderate'
            concurrent: 25
            duration: 120
          - name: 'heavy'
            concurrent: 50
            duration: 180

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore dependencies
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            dist
            ~/.npm
          key: ${{ needs.setup-and-validate.outputs.cache-key }}

      - name: Run load tests - ${{ matrix.load-profile.name }}
        env:
          TEST_ENVIRONMENT: ${{ needs.setup-and-validate.outputs.test-environment }}
          TEST_TYPE: load
          LOAD_CONCURRENT: ${{ matrix.load-profile.concurrent }}
          LOAD_DURATION: ${{ matrix.load-profile.duration }}
          DEV_API_URL: ${{ secrets.DEV_API_URL }}
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
          PROD_API_URL: ${{ secrets.PROD_API_URL }}
        run: |
          npm run test:load:${{ needs.setup-and-validate.outputs.test-environment }}

      - name: Analyze performance results
        run: |
          echo "Load Test Profile: ${{ matrix.load-profile.name }}" > load-analysis-${{ matrix.load-profile.name }}.txt
          echo "Concurrent Users: ${{ matrix.load-profile.concurrent }}" >> load-analysis-${{ matrix.load-profile.name }}.txt
          echo "Duration: ${{ matrix.load-profile.duration }}s" >> load-analysis-${{ matrix.load-profile.name }}.txt

          # Extract key metrics if report exists
          if [ -f "test-reports/${{ needs.setup-and-validate.outputs.test-environment }}/test-report-*.json" ]; then
            echo "Performance targets analysis completed" >> load-analysis-${{ matrix.load-profile.name }}.txt
          fi

      - name: Upload load test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: load-test-results-${{ matrix.load-profile.name }}-${{ needs.setup-and-validate.outputs.test-environment }}
          path: |
            test-reports/
            load-analysis-${{ matrix.load-profile.name }}.txt
          retention-days: 30

  # Job 5: Chaos Engineering Tests (Optional)
  chaos-tests:
    name: Chaos Engineering Tests
    runs-on: ubuntu-latest
    needs: [setup-and-validate, load-tests]
    if: |
      always() && 
      needs.load-tests.result == 'success' &&
      needs.setup-and-validate.outputs.test-environment != 'production' &&
      (needs.setup-and-validate.outputs.test-type == 'chaos' || needs.setup-and-validate.outputs.test-type == 'full' || github.event.inputs.enable_chaos == 'true')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Restore dependencies
        uses: actions/cache@v3
        with:
          path: |
            node_modules
            dist
            ~/.npm
          key: ${{ needs.setup-and-validate.outputs.cache-key }}

      - name: Run chaos engineering tests
        env:
          TEST_ENVIRONMENT: ${{ needs.setup-and-validate.outputs.test-environment }}
          TEST_TYPE: chaos
          DEV_API_URL: ${{ secrets.DEV_API_URL }}
          STAGING_API_URL: ${{ secrets.STAGING_API_URL }}
        run: |
          echo "⚠️ Running chaos engineering tests in ${{ needs.setup-and-validate.outputs.test-environment }}"
          npm run test:chaos:${{ needs.setup-and-validate.outputs.test-environment }}

      - name: Analyze resilience results
        run: |
          echo "Chaos Engineering Results" > chaos-analysis.txt
          echo "Environment: ${{ needs.setup-and-validate.outputs.test-environment }}" >> chaos-analysis.txt
          echo "Test Date: $(date)" >> chaos-analysis.txt

          if [ -f "test-reports/${{ needs.setup-and-validate.outputs.test-environment }}/test-report-*.json" ]; then
            echo "Resilience analysis completed" >> chaos-analysis.txt
          fi

      - name: Upload chaos test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: chaos-test-results-${{ needs.setup-and-validate.outputs.test-environment }}
          path: |
            test-reports/
            chaos-analysis.txt
          retention-days: 30

  # Job 6: Performance Analysis & Reporting
  performance-analysis:
    name: Performance Analysis & Quality Gates
    runs-on: ubuntu-latest
    needs: [setup-and-validate, smoke-tests, e2e-tests, load-tests, chaos-tests]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all test artifacts
        uses: actions/download-artifact@v3
        with:
          path: collected-results/

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci --prefer-offline --no-audit

      - name: Generate comprehensive performance report
        run: |
          mkdir -p final-reports

          echo "# HASIVU Platform - Performance Test Report" > final-reports/PERFORMANCE_REPORT.md
          echo "**Test Date:** $(date)" >> final-reports/PERFORMANCE_REPORT.md
          echo "**Environment:** ${{ needs.setup-and-validate.outputs.test-environment }}" >> final-reports/PERFORMANCE_REPORT.md
          echo "**Test Type:** ${{ needs.setup-and-validate.outputs.test-type }}" >> final-reports/PERFORMANCE_REPORT.md
          echo "" >> final-reports/PERFORMANCE_REPORT.md

          # Analyze results from each test phase
          echo "## Test Results Summary" >> final-reports/PERFORMANCE_REPORT.md

          if [[ "${{ needs.smoke-tests.result }}" == "success" ]]; then
            echo "✅ **Smoke Tests:** PASSED" >> final-reports/PERFORMANCE_REPORT.md
          else
            echo "❌ **Smoke Tests:** FAILED" >> final-reports/PERFORMANCE_REPORT.md
          fi

          if [[ "${{ needs.e2e-tests.result }}" == "success" ]]; then
            echo "✅ **E2E Tests:** PASSED" >> final-reports/PERFORMANCE_REPORT.md
          elif [[ "${{ needs.e2e-tests.result }}" == "failure" ]]; then
            echo "❌ **E2E Tests:** FAILED" >> final-reports/PERFORMANCE_REPORT.md
          else
            echo "⏭️ **E2E Tests:** SKIPPED" >> final-reports/PERFORMANCE_REPORT.md
          fi

          if [[ "${{ needs.load-tests.result }}" == "success" ]]; then
            echo "✅ **Load Tests:** PASSED" >> final-reports/PERFORMANCE_REPORT.md
          elif [[ "${{ needs.load-tests.result }}" == "failure" ]]; then
            echo "❌ **Load Tests:** FAILED" >> final-reports/PERFORMANCE_REPORT.md
          else
            echo "⏭️ **Load Tests:** SKIPPED" >> final-reports/PERFORMANCE_REPORT.md
          fi

          if [[ "${{ needs.chaos-tests.result }}" == "success" ]]; then
            echo "✅ **Chaos Tests:** PASSED" >> final-reports/PERFORMANCE_REPORT.md
          elif [[ "${{ needs.chaos-tests.result }}" == "failure" ]]; then
            echo "❌ **Chaos Tests:** FAILED" >> final-reports/PERFORMANCE_REPORT.md
          else
            echo "⏭️ **Chaos Tests:** SKIPPED" >> final-reports/PERFORMANCE_REPORT.md
          fi

          echo "" >> final-reports/PERFORMANCE_REPORT.md
          echo "## Collected Artifacts" >> final-reports/PERFORMANCE_REPORT.md
          find collected-results/ -name "*.json" -o -name "*.txt" | while read file; do
            echo "- \`$(basename "$file")\`" >> final-reports/PERFORMANCE_REPORT.md
          done

      - name: Determine overall status
        id: overall-status
        run: |
          if [[ "${{ needs.smoke-tests.result }}" == "failure" ]]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "reason=Smoke tests failed" >> $GITHUB_OUTPUT
          elif [[ "${{ needs.e2e-tests.result }}" == "failure" ]]; then
            echo "status=failure" >> $GITHUB_OUTPUT  
            echo "reason=E2E tests failed" >> $GITHUB_OUTPUT
          elif [[ "${{ needs.load-tests.result }}" == "failure" ]]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "reason=Load tests failed" >> $GITHUB_OUTPUT
          elif [[ "${{ needs.chaos-tests.result }}" == "failure" ]]; then
            echo "status=warning" >> $GITHUB_OUTPUT
            echo "reason=Chaos tests failed - system resilience needs improvement" >> $GITHUB_OUTPUT
          else
            echo "status=success" >> $GITHUB_OUTPUT
            echo "reason=All performance tests passed" >> $GITHUB_OUTPUT
          fi

      - name: Upload comprehensive report
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: comprehensive-performance-report-${{ needs.setup-and-validate.outputs.test-environment }}
          path: |
            final-reports/
            collected-results/
          retention-days: 90

      - name: Comment on PR (if applicable)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ steps.overall-status.outputs.status }}';
            const reason = '${{ steps.overall-status.outputs.reason }}';
            const environment = '${{ needs.setup-and-validate.outputs.test-environment }}';

            const statusEmoji = status === 'success' ? '✅' : status === 'warning' ? '⚠️' : '❌';

            const comment = `## ${statusEmoji} Performance Test Results

            **Environment:** \`${environment}\`
            **Status:** ${status.toUpperCase()}
            **Details:** ${reason}

            ### Test Coverage
            - Smoke Tests: ${{ needs.smoke-tests.result }}
            - E2E Tests: ${{ needs.e2e-tests.result }}  
            - Load Tests: ${{ needs.load-tests.result }}
            - Chaos Tests: ${{ needs.chaos-tests.result }}

            📊 [View detailed report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
            `;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Set job status
        if: steps.overall-status.outputs.status == 'failure'
        run: |
          echo "Performance tests failed: ${{ steps.overall-status.outputs.reason }}"
          exit 1

  # Job 7: Notification & Alerts
  notifications:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [setup-and-validate, performance-analysis]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'push')

    steps:
      - name: Send Slack notification
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              attachments: [{
                color: '${{ needs.performance-analysis.result == 'success' && 'good' || needs.performance-analysis.result == 'failure' && 'danger' || 'warning' }}',
                blocks: [
                  {
                    type: 'section',
                    text: {
                      type: 'mrkdwn',
                      text: `*HASIVU Platform Performance Tests*\n*Environment:* ${{ needs.setup-and-validate.outputs.test-environment }}\n*Status:* ${{ needs.performance-analysis.result }}\n*Branch:* ${process.env.GITHUB_REF_NAME}`
                    }
                  }
                ]
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
