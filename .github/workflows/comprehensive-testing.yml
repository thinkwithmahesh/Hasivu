name: Comprehensive Test Automation Suite

on:
  push:
    branches: [main, develop, 'release/*', 'feature/*']
  pull_request:
    branches: [main, develop]
  schedule:
    # Run comprehensive tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - performance
          - security
      environment:
        description: 'Environment to test against'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production

env:
  NODE_VERSION: '18.19.0'
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'

jobs:
  setup:
    name: Setup and Validate
    runs-on: ubuntu-latest
    outputs:
      test-suite: ${{ steps.determine-tests.outputs.test-suite }}
      should-run-unit: ${{ steps.determine-tests.outputs.should-run-unit }}
      should-run-integration: ${{ steps.determine-tests.outputs.should-run-integration }}
      should-run-e2e: ${{ steps.determine-tests.outputs.should-run-e2e }}
      should-run-performance: ${{ steps.determine-tests.outputs.should-run-performance }}
      should-run-security: ${{ steps.determine-tests.outputs.should-run-security }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine test suite to run
        id: determine-tests
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            TEST_SUITE="${{ github.event.inputs.test_suite }}"
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            TEST_SUITE="all"
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            # For PRs, run unit and integration tests
            TEST_SUITE="unit-integration"
          else
            # For pushes, determine based on changed files
            if git diff --name-only HEAD~1 HEAD | grep -E "\\.(ts|js|tsx|jsx)$" > /dev/null; then
              if git diff --name-only HEAD~1 HEAD | grep -E "test|spec" > /dev/null; then
                TEST_SUITE="all"
              else
                TEST_SUITE="unit-integration"
              fi
            else
              TEST_SUITE="unit"
            fi
          fi

          echo "test-suite=$TEST_SUITE" >> $GITHUB_OUTPUT

          # Determine which test types to run
          case $TEST_SUITE in
            "all")
              echo "should-run-unit=true" >> $GITHUB_OUTPUT
              echo "should-run-integration=true" >> $GITHUB_OUTPUT
              echo "should-run-e2e=true" >> $GITHUB_OUTPUT
              echo "should-run-performance=true" >> $GITHUB_OUTPUT
              echo "should-run-security=true" >> $GITHUB_OUTPUT
              ;;
            "unit")
              echo "should-run-unit=true" >> $GITHUB_OUTPUT
              echo "should-run-integration=false" >> $GITHUB_OUTPUT
              echo "should-run-e2e=false" >> $GITHUB_OUTPUT
              echo "should-run-performance=false" >> $GITHUB_OUTPUT
              echo "should-run-security=false" >> $GITHUB_OUTPUT
              ;;
            "integration")
              echo "should-run-unit=false" >> $GITHUB_OUTPUT
              echo "should-run-integration=true" >> $GITHUB_OUTPUT
              echo "should-run-e2e=false" >> $GITHUB_OUTPUT
              echo "should-run-performance=false" >> $GITHUB_OUTPUT
              echo "should-run-security=false" >> $GITHUB_OUTPUT
              ;;
            "e2e")
              echo "should-run-unit=false" >> $GITHUB_OUTPUT
              echo "should-run-integration=false" >> $GITHUB_OUTPUT
              echo "should-run-e2e=true" >> $GITHUB_OUTPUT
              echo "should-run-performance=false" >> $GITHUB_OUTPUT
              echo "should-run-security=false" >> $GITHUB_OUTPUT
              ;;
            "performance")
              echo "should-run-unit=false" >> $GITHUB_OUTPUT
              echo "should-run-integration=false" >> $GITHUB_OUTPUT
              echo "should-run-e2e=false" >> $GITHUB_OUTPUT
              echo "should-run-performance=true" >> $GITHUB_OUTPUT
              echo "should-run-security=false" >> $GITHUB_OUTPUT
              ;;
            "security")
              echo "should-run-unit=false" >> $GITHUB_OUTPUT
              echo "should-run-integration=false" >> $GITHUB_OUTPUT
              echo "should-run-e2e=false" >> $GITHUB_OUTPUT
              echo "should-run-performance=false" >> $GITHUB_OUTPUT
              echo "should-run-security=true" >> $GITHUB_OUTPUT
              ;;
            "unit-integration")
              echo "should-run-unit=true" >> $GITHUB_OUTPUT
              echo "should-run-integration=true" >> $GITHUB_OUTPUT
              echo "should-run-e2e=false" >> $GITHUB_OUTPUT
              echo "should-run-performance=false" >> $GITHUB_OUTPUT
              echo "should-run-security=false" >> $GITHUB_OUTPUT
              ;;
          esac

  lint-and-typecheck:
    name: Lint and Type Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

      - name: Run TypeScript type check
        run: npm run type-check

      - name: Check code formatting
        run: npm run format:check

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: [setup, lint-and-typecheck]
    if: needs.setup.outputs.should-run-unit == 'true'
    strategy:
      matrix:
        test-group: [auth, menu, orders, payments, rfid, nutrition, analytics]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup test environment
        run: |
          cp .env.test .env
          npm run db:generate

      - name: Run unit tests for ${{ matrix.test-group }}
        run: npm run test:unit -- --testPathPattern=${{ matrix.test-group }}
        env:
          NODE_ENV: test
          CI: true

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.test-group }}
          path: |
            coverage/
            test-results/
          retention-days: 7

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: ./coverage/lcov.info
          flags: unit-tests-${{ matrix.test-group }}
          name: unit-tests-${{ matrix.test-group }}

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [setup, lint-and-typecheck]
    if: needs.setup.outputs.should-run-integration == 'true'
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: hasivu_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup integration test environment
        run: |
          cp .env.test .env
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/hasivu_test" >> .env
          echo "REDIS_URL=redis://localhost:6379" >> .env

      - name: Run database migrations
        run: npm run db:migrate

      - name: Seed test data
        run: npm run db:seed

      - name: Run integration tests
        run: npm run test:integration
        env:
          NODE_ENV: test
          CI: true

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            coverage/
            test-results/
          retention-days: 7

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: ./coverage/lcov.info
          flags: integration-tests
          name: integration-tests

  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: [setup, lint-and-typecheck]
    if: needs.setup.outputs.should-run-e2e == 'true'
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
        user-journey: [student, parent, kitchen, admin]
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: hasivu_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps ${{ matrix.browser }}

      - name: Setup E2E test environment
        run: |
          cp .env.test .env
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/hasivu_test" >> .env
          echo "REDIS_URL=redis://localhost:6379" >> .env
          echo "TEST_BASE_URL=http://localhost:3000" >> .env
          echo "TEST_API_URL=http://localhost:3001" >> .env

      - name: Run database migrations and seed
        run: |
          npm run db:migrate
          npm run db:seed

      - name: Start application
        run: |
          npm run build
          npm start &
          sleep 30

      - name: Run E2E tests for ${{ matrix.user-journey }} on ${{ matrix.browser }}
        run: npm run test:e2e -- --browser=${{ matrix.browser }} --testPathPattern=${{ matrix.user-journey }}
        env:
          NODE_ENV: test
          CI: true
          BROWSER: ${{ matrix.browser }}

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results-${{ matrix.browser }}-${{ matrix.user-journey }}
          path: |
            test-results/
            playwright-report/
          retention-days: 7

      - name: Upload Playwright trace
        uses: actions/upload-artifact@v4
        if: failure()
        with:
          name: playwright-trace-${{ matrix.browser }}-${{ matrix.user-journey }}
          path: test-results/
          retention-days: 7

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [setup, lint-and-typecheck]
    if: needs.setup.outputs.should-run-performance == 'true'
    strategy:
      matrix:
        test-type: [load, stress, memory, database]
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: hasivu_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:${{ env.REDIS_VERSION }}
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup performance test environment
        run: |
          cp .env.test .env
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/hasivu_test" >> .env
          echo "REDIS_URL=redis://localhost:6379" >> .env
          echo "PERFORMANCE_TEST_URL=http://localhost:3001" >> .env

      - name: Run database migrations and seed
        run: |
          npm run db:migrate
          npm run db:seed

      - name: Start application
        run: |
          npm run build
          npm start &
          sleep 30

      - name: Run ${{ matrix.test-type }} performance tests
        run: npm run test:performance -- --testPathPattern=${{ matrix.test-type }}
        env:
          NODE_ENV: test
          CI: true
          TEST_TYPE: ${{ matrix.test-type }}
        timeout-minutes: 30

      - name: Upload performance test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results-${{ matrix.test-type }}
          path: |
            test-results/performance/
          retention-days: 30

      - name: Generate performance report
        if: always()
        run: npm run perf:report

      - name: Comment performance results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = './test-results/performance/performance-summary.json';

            if (fs.existsSync(path)) {
              const results = JSON.parse(fs.readFileSync(path, 'utf8'));
              const comment = `
            ## Performance Test Results - ${{ matrix.test-type }}

            | Metric | Value | Status |
            |--------|--------|--------|
            | Average Response Time | ${results.summary.averageResponseTime.toFixed(2)}ms | ${results.summary.averageResponseTime < 200 ? '✅' : '⚠️'} |
            | Max Response Time | ${results.summary.maxResponseTime.toFixed(2)}ms | ${results.summary.maxResponseTime < 1000 ? '✅' : '⚠️'} |
            | Error Rate | ${results.summary.errorRate.toFixed(2)}% | ${results.summary.errorRate < 1 ? '✅' : '❌'} |
            | Total Tests | ${results.summary.totalTests} | ℹ️ |
            | Performance Alerts | ${results.summary.totalAlerts} | ${results.summary.totalAlerts === 0 ? '✅' : '⚠️'} |

            ${results.recommendations.length > 0 ? '### Recommendations\n' + results.recommendations.map(r => `- ${r}`).join('\n') : ''}
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: [setup, lint-and-typecheck]
    if: needs.setup.outputs.should-run-security == 'true'
    strategy:
      matrix:
        security-type: [injection, authentication, authorization, data-protection]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup security test environment
        run: |
          cp .env.test .env
          echo "SECURITY_TEST_URL=http://localhost:3001" >> .env
          echo "SECURITY_API_KEY=test-security-key" >> .env

      - name: Start application
        run: |
          npm run build
          npm start &
          sleep 30

      - name: Run ${{ matrix.security-type }} security tests
        run: npm run test:security -- --testPathPattern=${{ matrix.security-type }}
        env:
          NODE_ENV: test
          CI: true
          SECURITY_TEST_TYPE: ${{ matrix.security-type }}
        timeout-minutes: 20

      - name: Upload security test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-test-results-${{ matrix.security-type }}
          path: |
            test-results/security/
          retention-days: 90

      - name: Check for critical vulnerabilities
        run: |
          if [ -f "test-results/security/final-security-report.json" ]; then
            CRITICAL_COUNT=$(cat test-results/security/final-security-report.json | jq '.summary.criticalCount')
            if [ "$CRITICAL_COUNT" -gt 0 ]; then
              echo "::error::Critical security vulnerabilities found: $CRITICAL_COUNT"
              exit 1
            fi
          fi

      - name: Comment security results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = './test-results/security/final-security-report.json';

            if (fs.existsSync(path)) {
              const results = JSON.parse(fs.readFileSync(path, 'utf8'));
              const summary = results.summary;

              const comment = `
            ## Security Test Results - ${{ matrix.security-type }}

            | Severity | Count | Status |
            |----------|--------|--------|
            | Critical | ${summary.criticalCount} | ${summary.criticalCount === 0 ? '✅' : '🚨'} |
            | High | ${summary.highCount} | ${summary.highCount === 0 ? '✅' : '⚠️'} |
            | Medium | ${summary.mediumCount} | ${summary.mediumCount < 5 ? '✅' : '⚠️'} |
            | Low | ${summary.lowCount} | ℹ️ |

            ${summary.criticalCount > 0 ? '### 🚨 CRITICAL VULNERABILITIES FOUND\nImmediate action required before deployment!' : ''}

            ${results.recommendations.length > 0 ? '### Security Recommendations\n' + results.recommendations.map(r => `- ${r}`).join('\n') : ''}
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, security-tests]
    if: always()
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-results/

      - name: Calculate overall test coverage
        run: |
          # Combine all coverage reports
          npm install -g lcov-result-merger
          find test-results/ -name "lcov.info" -exec lcov-result-merger '{}' + > combined-coverage.info

          # Calculate coverage percentage
          COVERAGE=$(lcov --summary combined-coverage.info 2>&1 | grep lines | cut -d' ' -f4 | sed 's/%//')
          echo "Overall test coverage: $COVERAGE%"
          echo "COVERAGE=$COVERAGE" >> $GITHUB_ENV

      - name: Evaluate quality gate
        run: |
          QUALITY_SCORE=0

          # Unit test coverage (40 points)
          if [ "${COVERAGE:-0}" -ge 95 ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 40))
          elif [ "${COVERAGE:-0}" -ge 90 ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 35))
          elif [ "${COVERAGE:-0}" -ge 80 ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 30))
          else
            QUALITY_SCORE=$((QUALITY_SCORE + 20))
          fi

          # Integration tests (20 points)
          if [ "${{ needs.integration-tests.result }}" = "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 20))
          elif [ "${{ needs.integration-tests.result }}" = "skipped" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 15))
          fi

          # E2E tests (20 points)
          if [ "${{ needs.e2e-tests.result }}" = "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 20))
          elif [ "${{ needs.e2e-tests.result }}" = "skipped" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 15))
          fi

          # Performance tests (10 points)
          if [ "${{ needs.performance-tests.result }}" = "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 10))
          elif [ "${{ needs.performance-tests.result }}" = "skipped" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 8))
          fi

          # Security tests (10 points)
          if [ "${{ needs.security-tests.result }}" = "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 10))
          elif [ "${{ needs.security-tests.result }}" = "skipped" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE + 8))
          fi

          echo "Quality Score: $QUALITY_SCORE/100"
          echo "QUALITY_SCORE=$QUALITY_SCORE" >> $GITHUB_ENV

          # Fail if quality gate is not met
          if [ "$QUALITY_SCORE" -lt 90 ]; then
            echo "::error::Quality gate failed. Score: $QUALITY_SCORE/100 (minimum: 90)"
            exit 1
          fi

      - name: Update README with quality badge
        if: github.ref == 'refs/heads/main'
        run: |
          # This would update the README with current quality score
          echo "Quality Score: $QUALITY_SCORE% | Coverage: $COVERAGE%" > quality-status.txt

      - name: Create deployment gate status
        uses: actions/github-script@v7
        with:
          script: |
            const qualityScore = process.env.QUALITY_SCORE;
            const coverage = process.env.COVERAGE;

            // Create or update deployment status
            github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: qualityScore >= 90 ? 'success' : 'failure',
              target_url: `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
              description: `Quality: ${qualityScore}% | Coverage: ${coverage}%`,
              context: 'quality-gate'
            });

  notify-teams:
    name: Notify Teams
    runs-on: ubuntu-latest
    needs: [quality-gate]
    if: always() && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
    steps:
      - name: Send Slack notification
        if: env.SLACK_WEBHOOK_URL
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ needs.quality-gate.result }}
          channel: '#hasivu-testing'
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
          fields: repo,message,commit,author,action,eventName,ref,workflow

      - name: Send email notification for failures
        if: failure() && github.ref == 'refs/heads/main'
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.SMTP_USERNAME }}
          password: ${{ secrets.SMTP_PASSWORD }}
          subject: 'HASIVU Platform - Test Suite Failed'
          to: ${{ secrets.TEAM_EMAIL }}
          from: 'HASIVU CI/CD <ci@hasivu.com>'
          body: |
            The comprehensive test suite has failed for commit ${{ github.sha }}.

            Please check the GitHub Actions logs for details:
            https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}

            Quality Score: ${{ env.QUALITY_SCORE }}/100
            Test Coverage: ${{ env.COVERAGE }}%
