/**
 * HASIVU Platform - AWS S3 Service
 * Production-ready S3 integration with multipart upload support and comprehensive file management
 * Handles uploads, downloads, presigned URLs, and file operations for the HASIVU platform
 */

import {
  S3Client,
  PutObjectCommand,
  GetObjectCommand,
  DeleteObjectCommand,
  HeadObjectCommand,
  CreateMultipartUploadCommand,
  UploadPartCommand,
  CompleteMultipartUploadCommand,
  AbortMultipartUploadCommand,
  ListObjectsV2Command,
  CopyObjectCommand
} from '@aws-sdk/client-s3';
import { getSignedUrl } from '@aws-sdk/s3-request-presigner';
import { Upload } from '@aws-sdk/lib-storage';
import crypto from 'crypto';
import path from 'path';
// import { LoggerService } from '../logger.service';  // Logger import temporarily unavailable
const logger = {
  info: (message: string, data?: any) => console.log(message, data),
  warn: (message: string, data?: any) => console.warn(message, data),
  error: (message: string, data?: any) => console.error(message, data),
  debug: (message: string, data?: any) => console.debug(message, data)
};
import { config } from '../../config/environment';

/**
 * S3 Upload Options
 */
export interface S3UploadOptions {
  contentType?: string;
  maxFileSize?: number; // in bytes
  allowedTypes?: string[];
  metadata?: Record<string, string>;
  tags?: Record<string, string>;
  cacheControl?: string;
  acl?: 'private' | 'public-read' | 'public-read-write';
  serverSideEncryption?: 'AES256' | 'aws:kms';
  kmsKeyId?: string;
  storageClass?: 'STANDARD' | 'STANDARD_IA' | 'ONEZONE_IA' | 'GLACIER' | 'DEEP_ARCHIVE';
}

/**
 * S3 Upload Result
 */
export interface S3UploadResult {
  key: string;
  bucket: string;
  location: string;
  etag: string;
  versionId?: string;
  size: number;
  contentType: string;
  timestamp: number;
  metadata?: Record<string, string>;
}

/**
 * S3 Download Options
 */
export interface S3DownloadOptions {
  range?: string; // bytes range (e.g., "bytes=0-1023")
  versionId?: string;
  responseContentType?: string;
  responseContentDisposition?: string;
  responseContentEncoding?: string;
  responseExpires?: Date;
  responseCacheControl?: string;
}

/**
 * S3 File Info
 */
export interface S3FileInfo {
  key: string;
  size: number;
  lastModified: Date;
  etag: string;
  contentType: string;
  metadata?: Record<string, string>;
  storageClass: string;
  versionId?: string;
}

/**
 * Presigned URL Options
 */
export interface PresignedUrlOptions {
  expiresIn?: number; // seconds
  responseContentType?: string;
  responseContentDisposition?: string;
  conditions?: Array<any>;
}

/**
 * Multipart Upload Info
 */
export interface MultipartUploadInfo {
  uploadId: string;
  key: string;
  bucket: string;
  parts: MultipartPart[];
  maxPartSize: number;
  minPartSize: number;
}

export interface MultipartPart {
  partNumber: number;
  etag: string;
  size: number;
}

/**
 * Base64 Image Data
 */
export interface Base64ImageData {
  data: string; // base64 string without data URL prefix
  mimeType: string;
  filename?: string;
}

/**
 * S3 Service Error
 */
export class S3ServiceError extends Error {
  public readonly code: string;
  public readonly statusCode: number;
  public readonly key?: string;

  constructor(message: string, code: string = 'S3_ERROR', statusCode: number = 500, key?: string) {
    super(message);
    this.name = 'S3ServiceError';
    this.code = code;
    this.statusCode = statusCode;
    this.key = key;
    
    // Ensure proper prototype chain for instanceof checks
    Object.setPrototypeOf(this, S3ServiceError.prototype);
  }
}

/**
 * AWS S3 Service
 * Singleton service for handling all S3 file operations
 */
export class S3Service {
  private static instance: S3Service;
  private readonly client: S3Client;
  private readonly bucketName: string;
  private readonly region: string;
  private readonly baseUrl: string;
  
  // Default configuration
  private readonly defaultUploadOptions: S3UploadOptions = {
    maxFileSize: 10 * 1024 * 1024, // 10MB
    allowedTypes: [
      'image/jpeg',
      'image/png',
      'image/gif',
      'image/webp',
      'application/pdf',
      'text/plain',
      'text/csv',
      'application/json'
    ],
    cacheControl: 'public, max-age=31536000', // 1 year
    acl: 'private',
    serverSideEncryption: 'AES256',
    storageClass: 'STANDARD'
  };

  private readonly multipartThreshold = 100 * 1024 * 1024; // 100MB
  private readonly partSize = 10 * 1024 * 1024; // 10MB per part

  private constructor() {
    this.bucketName = (config.aws as any).s3?.bucketName || config.aws.s3Bucket;
    this.region = config.aws.region;
    this.baseUrl = `https://${this.bucketName}.s3.${this.region}.amazonaws.com`;

    this.client = new S3Client({
      region: this.region,
      credentials: {
        accessKeyId: config.aws.accessKeyId,
        secretAccessKey: config.aws.secretAccessKey
      }
    });

    logger.info('S3Service initialized', {
      bucket: this.bucketName,
      region: this.region,
      baseUrl: this.baseUrl
    });
  }

  /**
   * Get singleton instance
   */
  public static getInstance(): S3Service {
    if (!S3Service.instance) {
      S3Service.instance = new S3Service();
    }
    return S3Service.instance;
  }

  /**
   * Generate a secure file key with proper folder structure
   */
  private generateFileKey(
    category: string,
    entityId: string,
    filename: string,
    userId?: string
  ): string {
    const timestamp = Date.now();
    const randomId = crypto.randomBytes(8).toString('hex');
    const extension = path.extname(filename);
    const baseName = path.basename(filename, extension);
    const sanitizedBaseName = baseName.replace(/[^a-zA-Z0-9_-]/g, '_');
    const sanitizedFilename = `${sanitizedBaseName}${extension}`;

    let key = `${category}/${entityId}`;
    if (userId) {
      key += `/${userId}`;
    }
    key += `/${timestamp}_${randomId}_${sanitizedFilename}`;

    return key;
  }

  /**
   * Validate upload options and file
   */
  private validateUpload(buffer: Buffer, options: S3UploadOptions): void {
    // Check file size
    if (options.maxFileSize && buffer.length > options.maxFileSize) {
      throw new S3ServiceError(
        `File size ${buffer.length} bytes exceeds maximum allowed size ${options.maxFileSize} bytes`,
        'FILE_TOO_LARGE',
        413
      );
    }

    // Check content type
    if (options.allowedTypes && options.contentType && !options.allowedTypes.includes(options.contentType)) {
      throw new S3ServiceError(
        `File type ${options.contentType} not allowed. Allowed types: ${options.allowedTypes.join(', ')}`,
        'INVALID_FILE_TYPE',
        400
      );
    }
  }

  /**
   * Upload file to S3
   */
  public async uploadFile(
    category: string,
    entityId: string,
    filename: string,
    buffer: Buffer,
    options: S3UploadOptions = {},
    userId?: string
  ): Promise<S3UploadResult> {
    const startTime = Date.now();
    
    try {
      // Merge with defaults
      const uploadOptions = { ...this.defaultUploadOptions, ...options };
      
      // Validate upload
      this.validateUpload(buffer, uploadOptions);

      // Generate secure key
      const key = this.generateFileKey(category, entityId, filename, userId);

      // Prepare S3 parameters
      const uploadParams: any = {
        Bucket: this.bucketName,
        Key: key,
        Body: buffer,
        ContentType: uploadOptions.contentType || 'application/octet-stream',
        CacheControl: uploadOptions.cacheControl,
        ServerSideEncryption: uploadOptions.serverSideEncryption,
        StorageClass: uploadOptions.storageClass,
        Metadata: uploadOptions.metadata || {}
      };

      // Add KMS key if specified
      if (uploadOptions.serverSideEncryption === 'aws:kms' && uploadOptions.kmsKeyId) {
        uploadParams.SSEKMSKeyId = uploadOptions.kmsKeyId;
      }

      // Add tags if specified
      if (uploadOptions.tags && Object.keys(uploadOptions.tags).length > 0) {
        uploadParams.Tagging = Object.entries(uploadOptions.tags)
          .map(([k, v]) => `${k}=${v}`)
          .join('&');
      }

      // Use multipart upload for large files
      if (buffer.length > this.multipartThreshold) {
        return await this.multipartUpload(key, buffer, uploadParams);
      }

      // Single part upload
      const command = new PutObjectCommand(uploadParams);
      const response = await this.client.send(command);

      const result: S3UploadResult = {
        key,
        bucket: this.bucketName,
        location: `${this.baseUrl}/${key}`,
        etag: response.ETag || '',
        versionId: response.VersionId,
        size: buffer.length,
        contentType: uploadOptions.contentType || 'application/octet-stream',
        timestamp: Date.now(),
        metadata: uploadOptions.metadata
      };

      const duration = Date.now() - startTime;
      logger.info('File uploaded successfully', {
        key,
        size: buffer.length,
        contentType: uploadOptions.contentType,
        duration: `${duration}ms`
      });

      return result;
    } catch (error: any) {
      const duration = Date.now() - startTime;
      logger.error('S3 upload failed', {
        category,
        entityId,
        filename,
        error: error instanceof Error ? error.message : String(error),
        duration: `${duration}ms`
      });

      if (error instanceof S3ServiceError) {
        throw error;
      }

      throw new S3ServiceError(
        `S3 upload failed: ${error.message}`,
        'UPLOAD_FAILED',
        500
      );
    }
  }

  /**
   * Upload base64 image to S3
   */
  public async uploadBase64Image(
    category: string,
    entityId: string,
    imageData: Base64ImageData,
    options: S3UploadOptions = {},
    userId?: string
  ): Promise<S3UploadResult> {
    try {
      // Convert base64 to buffer
      const buffer = Buffer.from(imageData.data, 'base64');
      
      // Determine filename and content type
      const extension = imageData.mimeType.split('/')[1];
      let filename = imageData.filename;
      if (!filename) {
        filename = `image.${extension}`;
      }

      const uploadOptions = {
        ...options,
        contentType: imageData.mimeType
      };

      return await this.uploadFile(category, entityId, filename, buffer, uploadOptions, userId);
    } catch (error: any) {
      logger.error('Base64 image upload failed', {
        category,
        entityId,
        mimeType: imageData.mimeType,
        error: error instanceof Error ? error.message : String(error)
      });

      if (error instanceof S3ServiceError) {
        throw error;
      }

      throw new S3ServiceError(
        `Base64 image upload failed: ${error.message}`,
        'BASE64_UPLOAD_FAILED',
        500
      );
    }
  }

  /**
   * Multipart upload for large files
   */
  private async multipartUpload(key: string, buffer: Buffer, params: any): Promise<S3UploadResult> {
    try {
      const upload = new Upload({
        client: this.client,
        params: {
          ...params,
          Key: key,
          Body: buffer
        },
        partSize: this.partSize,
        leavePartsOnError: false
      });

      const result = await upload.done();
      
      return {
        key,
        bucket: this.bucketName,
        location: `${this.baseUrl}/${key}`,
        etag: result.ETag || '',
        versionId: result.VersionId,
        size: buffer.length,
        contentType: params.ContentType,
        timestamp: Date.now(),
        metadata: params.Metadata
      };
    } catch (error: any) {
      throw new S3ServiceError(
        `Multipart upload failed: ${error.message}`,
        'MULTIPART_UPLOAD_FAILED',
        500,
        key
      );
    }
  }

  /**
   * Download file from S3
   */
  public async downloadFile(key: string, options: S3DownloadOptions = {}): Promise<Buffer> {
    try {
      const command = new GetObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        Range: options.range,
        VersionId: options.versionId,
        ResponseContentType: options.responseContentType,
        ResponseContentDisposition: options.responseContentDisposition,
        ResponseContentEncoding: options.responseContentEncoding,
        ResponseExpires: options.responseExpires,
        ResponseCacheControl: options.responseCacheControl
      });

      const response = await this.client.send(command);
      
      if (!response.Body) {
        throw new S3ServiceError(
          `File not found: ${key}`,
          'FILE_NOT_FOUND',
          404,
          key
        );
      }

      // Convert stream to buffer
      const chunks: Buffer[] = [];
      const stream = response.Body as any;
      
      for await (const chunk of stream) {
        chunks.push(chunk);
      }

      const buffer = Buffer.concat(chunks);

      logger.info('File downloaded successfully', {
        key,
        size: buffer.length,
        contentType: response.ContentType
      });

      return buffer;
    } catch (error: any) {
      logger.error('S3 download failed', {
        key,
        error: error instanceof Error ? error.message : String(error)
      });

      if (error instanceof S3ServiceError) {
        throw error;
      }

      throw new S3ServiceError(
        `Failed to download file: ${error.message}`,
        'DOWNLOAD_FAILED',
        500,
        key
      );
    }
  }

  /**
   * Generate presigned URL for file upload
   */
  public async generateUploadUrl(
    category: string,
    entityId: string,
    filename: string,
    options: PresignedUrlOptions = {},
    userId?: string
  ): Promise<{ uploadUrl: string; key: string; fields?: Record<string, string> }> {
    try {
      const key = this.generateFileKey(category, entityId, filename, userId);
      const expiresIn = options.expiresIn || 3600; // 1 hour default

      const command = new PutObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        ContentType: options.responseContentType,
        ContentDisposition: options.responseContentDisposition
      });

      const uploadUrl = await getSignedUrl(this.client, command, { expiresIn });

      const finalUrl = `${this.baseUrl}/${key}`;
      
      logger.info('Presigned upload URL generated', {
        key,
        expiresIn,
        finalUrl
      });

      return {
        uploadUrl,
        key,
        fields: {
          key,
          'Content-Type': options.responseContentType || '',
          'Content-Disposition': options.responseContentDisposition || ''
        }
      };
    } catch (error: any) {
      logger.error('Failed to generate presigned URL', {
        category,
        entityId,
        filename,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to generate presigned URL: ${error.message}`,
        'PRESIGNED_URL_FAILED',
        500
      );
    }
  }

  /**
   * Generate presigned URL for file download
   */
  public async generateDownloadUrl(
    key: string,
    options: PresignedUrlOptions = {}
  ): Promise<string> {
    try {
      const expiresIn = options.expiresIn || 3600; // 1 hour default

      const command = new GetObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        ResponseContentType: options.responseContentType,
        ResponseContentDisposition: options.responseContentDisposition
      });

      const downloadUrl = await getSignedUrl(this.client, command, { expiresIn });

      logger.info('Presigned download URL generated', {
        key,
        expiresIn
      });

      return downloadUrl;
    } catch (error: any) {
      logger.error('Failed to generate presigned download URL', {
        key,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to generate presigned download URL: ${error.message}`,
        'PRESIGNED_DOWNLOAD_URL_FAILED',
        500,
        key
      );
    }
  }

  /**
   * Delete file from S3
   */
  public async deleteFile(key: string, versionId?: string): Promise<void> {
    try {
      const command = new DeleteObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        VersionId: versionId
      });

      await this.client.send(command);

      logger.info('File deleted successfully', {
        key,
        versionId
      });
    } catch (error: any) {
      logger.error('S3 delete failed', {
        key,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to delete file: ${error.message}`,
        'DELETE_FAILED',
        500,
        key
      );
    }
  }

  /**
   * Check if file exists
   */
  public async fileExists(key: string, versionId?: string): Promise<boolean> {
    try {
      const command = new HeadObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        VersionId: versionId
      });

      await this.client.send(command);
      return true;
    } catch (error: any) {
      if (error.name === 'NotFound' || error.$metadata?.httpStatusCode === 404) {
        return false;
      }

      logger.error('Error checking file existence', {
        key,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Error checking file existence: ${error.message}`,
        'FILE_CHECK_FAILED',
        500,
        key
      );
    }
  }

  /**
   * Get file information
   */
  public async getFileInfo(key: string, versionId?: string): Promise<S3FileInfo> {
    try {
      const command = new HeadObjectCommand({
        Bucket: this.bucketName,
        Key: key,
        VersionId: versionId
      });

      const response = await this.client.send(command);

      return {
        key,
        size: response.ContentLength || 0,
        lastModified: response.LastModified || new Date(),
        etag: response.ETag || '',
        contentType: response.ContentType || 'application/octet-stream',
        metadata: response.Metadata,
        storageClass: response.StorageClass || 'STANDARD',
        versionId: response.VersionId
      };
    } catch (error: any) {
      if (error.name === 'NotFound' || error.$metadata?.httpStatusCode === 404) {
        throw new S3ServiceError(
          `File not found: ${key}`,
          'FILE_NOT_FOUND',
          404,
          key
        );
      }

      logger.error('Failed to get file info', {
        key,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to get file info: ${error.message}`,
        'FILE_INFO_FAILED',
        500,
        key
      );
    }
  }

  /**
   * List files with prefix
   */
  public async listFiles(prefix: string, maxKeys: number = 1000): Promise<S3FileInfo[]> {
    try {
      const command = new ListObjectsV2Command({
        Bucket: this.bucketName,
        Prefix: prefix,
        MaxKeys: maxKeys
      });

      const response = await this.client.send(command);
      
      if (!response.Contents) {
        return [];
      }

      return response.Contents.map(obj => ({
        key: obj.Key || '',
        size: obj.Size || 0,
        lastModified: obj.LastModified || new Date(),
        etag: obj.ETag || '',
        contentType: 'application/octet-stream',
        storageClass: obj.StorageClass || 'STANDARD'
      }));
    } catch (error: any) {
      logger.error('Failed to list files', {
        prefix,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to list files: ${error.message}`,
        'LIST_FILES_FAILED',
        500
      );
    }
  }

  /**
   * Copy file within S3
   */
  public async copyFile(
    sourceKey: string,
    destinationKey: string,
    options: S3UploadOptions = {}
  ): Promise<S3UploadResult> {
    try {
      const command = new CopyObjectCommand({
        Bucket: this.bucketName,
        CopySource: `${this.bucketName}/${sourceKey}`,
        Key: destinationKey,
        MetadataDirective: 'REPLACE',
        Metadata: options.metadata || {},
        ContentType: options.contentType,
        CacheControl: options.cacheControl,
        ServerSideEncryption: options.serverSideEncryption,
        StorageClass: options.storageClass
      });

      const response = await this.client.send(command);

      // Get file info to return complete result
      const fileInfo = await this.getFileInfo(destinationKey);

      const result: S3UploadResult = {
        key: destinationKey,
        bucket: this.bucketName,
        location: `${this.baseUrl}/${destinationKey}`,
        etag: response.CopyObjectResult?.ETag || '',
        versionId: response.VersionId,
        size: fileInfo.size,
        contentType: fileInfo.contentType,
        timestamp: Date.now(),
        metadata: options.metadata
      };

      logger.info('File copied successfully', {
        sourceKey,
        destinationKey,
        size: fileInfo.size
      });

      return result;
    } catch (error: any) {
      logger.error('S3 copy failed', {
        sourceKey,
        destinationKey,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to copy file: ${error.message}`,
        'COPY_FAILED',
        500,
        sourceKey
      );
    }
  }

  /**
   * Upload delivery photo (specialized method)
   */
  public async uploadDeliveryPhoto(
    orderId: string,
    imageBuffer: Buffer,
    filename: string,
    userId?: string
  ): Promise<S3UploadResult> {
    try {
      const options: S3UploadOptions = {
        contentType: 'image/jpeg',
        maxFileSize: 5 * 1024 * 1024, // 5MB
        allowedTypes: ['image/jpeg', 'image/png', 'image/webp'],
        metadata: {
          orderId,
          uploadedBy: userId || 'system',
          uploadedAt: new Date().toISOString()
        },
        tags: {
          category: 'delivery',
          orderId,
          type: 'photo'
        }
      };

      return await this.uploadFile('delivery', orderId, filename, imageBuffer, options, userId);
    } catch (error: any) {
      logger.error('Failed to upload delivery photo', {
        orderId,
        filename,
        error: error instanceof Error ? error.message : String(error)
      });

      throw new S3ServiceError(
        `Failed to upload delivery photo: ${error.message}`,
        'DELIVERY_PHOTO_UPLOAD_FAILED',
        500
      );
    }
  }

  /**
   * Health check for S3 service
   */
  public async healthCheck(): Promise<{
    status: 'healthy' | 'unhealthy';
    timestamp: number;
    bucketAccessible: boolean;
    error?: string;
  }> {
    try {
      // Try to list objects with limit 1 to test connectivity
      const command = new ListObjectsV2Command({
        Bucket: this.bucketName,
        MaxKeys: 1
      });

      await this.client.send(command);

      return {
        status: 'healthy',
        timestamp: Date.now(),
        bucketAccessible: true
      };
    } catch (error: any) {
      logger.error('S3 health check failed', {
        bucket: this.bucketName,
        error: error instanceof Error ? error.message : String(error)
      });

      return {
        status: 'unhealthy',
        timestamp: Date.now(),
        bucketAccessible: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }

  /**
   * Get service configuration (safe for logging)
   */
  public getServiceInfo(): {
    bucket: string;
    region: string;
    baseUrl: string;
    multipartThreshold: number;
    partSize: number;
    defaultMaxFileSize: number;
  } {
    return {
      bucket: this.bucketName,
      region: this.region,
      baseUrl: this.baseUrl,
      multipartThreshold: this.multipartThreshold,
      partSize: this.partSize,
      defaultMaxFileSize: this.defaultUploadOptions.maxFileSize || 0
    };
  }
}

// Export singleton instance
export const s3Service = S3Service.getInstance();