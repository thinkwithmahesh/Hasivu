/**
 * HASIVU Epic 3 â†’ Story 5: AI Insights Engine
 *
 * Intelligent insights generation service providing:
 * - AI-powered anomaly detection and alerting
 * - Natural language insights generation using LLMs
 * - Automated trend analysis and pattern recognition
 * - Recommendation engine for operational improvements
 * - Contextual insights based on school performance data
 *
 * Production-ready implementation with enterprise AI capabilities
 *
 * @author HASIVU Development Team
 * @version 1.0.0
 * @since 2024-09-18
 */

import { EventEmitter } from 'events';
import { v4 as uuidv4 } from 'uuid';
import { BedrockRuntimeClient, InvokeModelCommand } from '@aws-sdk/client-bedrock-runtime';
import { SageMakerRuntimeClient, InvokeEndpointCommand } from '@aws-sdk/client-sagemaker-runtime';
import { logger } from '../utils/logger';
import { MetricsCollector } from './metrics.service';
import { CacheManager } from './cache-manager.service';

/**
 * AI-generated insight interface
 */
export interface AIGeneratedInsight {
  id: string;
  type: 'trend' | 'anomaly' | 'recommendation' | 'prediction' | 'correlation';
  priority: 'low' | 'medium' | 'high' | 'critical';
  confidence: number;
  title: string;
  description: string;
  details: string;
  visualizations: VisualizationConfig[];
  actionItems: ActionItem[];
  dataPoints: any[] | undefined;
  metadata: {
    algorithm: string;
    modelVersion: string;
    generatedAt: Date;
    reviewStatus: 'pending' | 'approved' | 'rejected';
  };
}

/**
 * Anomaly detection configuration
 */
export interface AnomalyDetectionConfig {
  sensitivity: number;
  algorithm: 'isolation_forest' | 'one_class_svm' | 'local_outlier_factor' | 'elliptic_envelope';
  contamination?: number;
  seasonality?: boolean;
  trendAware?: boolean;
}

/**
 * Prediction configuration
 */
export interface PredictionConfig {
  horizon: string; // e.g., '7d', '30d', '90d'
  confidence: number;
  algorithm?: 'arima' | 'lstm' | 'prophet' | 'linear_regression';
  includeSeasonality?: boolean;
  includeHolidays?: boolean;
}

/**
 * Correlation analysis configuration
 */
export interface CorrelationConfig {
  threshold: number;
  method: 'pearson' | 'spearman' | 'kendall';
  includeNonLinear?: boolean;
  maxVariables?: number;
}

/**
 * Recommendation configuration
 */
export interface RecommendationConfig {
  context: string;
  priority: 'cost_savings' | 'efficiency' | 'quality' | 'business_impact';
  maxRecommendations?: number;
  includeImplementationSteps?: boolean;
}

/**
 * Trend analysis result
 */
export interface TrendAnalysis {
  metric: string;
  direction: 'up' | 'down' | 'stable';
  strength: number;
  significance: number;
  seasonality?: {
    detected: boolean;
    period?: number;
    strength?: number;
  };
  changePoints: Array<{
    date: Date;
    magnitude: number;
    confidence: number;
  }>;
  forecast: Array<{
    date: Date;
    value: number;
    confidence_lower: number;
    confidence_upper: number;
  }>;
}

/**
 * Anomaly detection result
 */
export interface AnomalyResult {
  dataPoint: any;
  score: number;
  isAnomaly: boolean;
  severity: 'low' | 'medium' | 'high' | 'critical';
  explanation: string;
  similarPatterns: any[] | undefined;
  recommendedActions: string[];
}

/**
 * AI Insights Engine Service
 */
export class AIInsightsEngine extends EventEmitter {
  private readonly metrics = new MetricsCollector();
  private readonly cache = new CacheManager();

  private readonly bedrockClient: BedrockRuntimeClient;
  private readonly sagemakerClient: SageMakerRuntimeClient;

  private isInitialized = false;
  private readonly modelConfigs = new Map<string, any>();
  private readonly insightCache = new Map<string, AIGeneratedInsight[]>();

  constructor(
    private readonly config: {
      awsRegion: string;
      bedrockModel: string;
      sagemakerEndpoints: {
        anomalyDetection?: string;
        timeSeriesForecasting?: string;
        nlpInsights?: string;
      };
      cacheTimeout: number;
      maxInsightsPerRequest: number;
      confidenceThreshold: number;
    }
  ) {
    super();

    this.bedrockClient = new BedrockRuntimeClient({
      region: this.config.awsRegion
    });

    this.sagemakerClient = new SageMakerRuntimeClient({
      region: this.config.awsRegion
    });

    this.setupEventHandlers();
  }

  /**
   * Initialize the AI insights engine
   */
  async initialize(): Promise<void> {
    try {
      logger.info('Initializing AI Insights Engine...');

      // Test model connectivity
      await this.testModelConnections();

      // Load model configurations
      await this.loadModelConfigurations();

      this.isInitialized = true;

      logger.info('AI Insights Engine initialized successfully', {
        bedrockModel: this.config.bedrockModel,
        sagemakerEndpoints: Object.keys(this.config.sagemakerEndpoints),
        confidenceThreshold: this.config.confidenceThreshold
      });

      this.emit('initialized');

    } catch (error: unknown) {
      logger.error('Failed to initialize AI Insights Engine', { error });
      throw error;
    }
  }

  /**
   * Analyze trends in time series data
   */
  async analyzeTrends(
    data: Record<string, any[]>,
    dateRange: { start: Date; end: Date },
    config: { minDataPoints?: number; significanceLevel?: number } = {}
  ): Promise<AIGeneratedInsight[]> {
    try {
      logger.debug('Analyzing trends', {
        dataSourcesCount: Object.keys(data).length,
        dateRange
      });

      if (!this.isInitialized) {
        throw new Error('AI Insights Engine not initialized');
      }

      const insights: AIGeneratedInsight[] = [];

      for (const [sourceName, sourceData] of Object.entries(data)) {
        if (!Array.isArray(sourceData) || sourceData.length < (config.minDataPoints || 10)) {
          continue;
        }

        // Perform trend analysis
        const trendAnalysis = await this.performTrendAnalysis(sourceData, sourceName);

        if (trendAnalysis.significance >= (config.significanceLevel || 0.05)) {
          const insight = await this.generateTrendInsight(trendAnalysis, sourceName);
          if (insight.confidence >= this.config.confidenceThreshold) {
            insights.push(insight);
          }
        }
      }

      // Sort by significance and confidence
      insights.sort((a, b) => b.confidence - a.confidence);

      logger.info('Trend analysis completed', {
        trendsDetected: insights.length,
        significantTrends: insights.filter(i => i.priority === 'high' || i.priority === 'critical').length
      });

      this.metrics.gauge('ai_insights.trends.detected', insights.length);

      return insights.slice(0, this.config.maxInsightsPerRequest);

    } catch (error: unknown) {
      logger.error('Failed to analyze trends', { error });
      this.metrics.increment('ai_insights.trends.failed');
      return [];
    }
  }

  /**
   * Detect anomalies in data using ML models
   */
  async detectAnomalies(
    data: Record<string, any[]>,
    config: AnomalyDetectionConfig
  ): Promise<AIGeneratedInsight[]> {
    try {
      logger.debug('Detecting anomalies', {
        algorithm: config.algorithm,
        sensitivity: config.sensitivity
      });

      const insights: AIGeneratedInsight[] = [];

      for (const [sourceName, sourceData] of Object.entries(data)) {
        if (!Array.isArray(sourceData) || sourceData.length < 20) {
          continue;
        }

        // Detect anomalies using the specified algorithm
        const anomalies = await this.detectAnomaliesInDataset(sourceData, config);

        for (const anomaly of anomalies) {
          if (anomaly.isAnomaly && anomaly.score >= config.sensitivity) {
            const insight = await this.generateAnomalyInsight(anomaly, sourceName, config);
            if (insight.confidence >= this.config.confidenceThreshold) {
              insights.push(insight);
            }
          }
        }
      }

      // Sort by severity and score
      insights.sort((a, b) => {
        const severityOrder = { critical: 4, high: 3, medium: 2, low: 1 };
        const aSeverity = severityOrder[a.priority as keyof typeof severityOrder];
        const bSeverity = severityOrder[b.priority as keyof typeof severityOrder];
        return bSeverity - aSeverity || b.confidence - a.confidence;
      });

      logger.info('Anomaly detection completed', {
        anomaliesDetected: insights.length,
        criticalAnomalies: insights.filter(i => i.priority === 'critical').length
      });

      this.metrics.gauge('ai_insights.anomalies.detected', insights.length);

      return insights.slice(0, this.config.maxInsightsPerRequest);

    } catch (error: unknown) {
      logger.error('Failed to detect anomalies', { error });
      this.metrics.increment('ai_insights.anomalies.failed');
      return [];
    }
  }

  /**
   * Generate predictions using time series forecasting
   */
  async generatePredictions(
    data: Record<string, any[]>,
    config: PredictionConfig
  ): Promise<AIGeneratedInsight[]> {
    try {
      logger.debug('Generating predictions', {
        horizon: config.horizon,
        algorithm: config.algorithm || 'auto'
      });

      const insights: AIGeneratedInsight[] = [];

      for (const [sourceName, sourceData] of Object.entries(data)) {
        if (!Array.isArray(sourceData) || sourceData.length < 30) {
          continue;
        }

        // Generate predictions
        const predictions = await this.generateTimeSeriesPredictions(sourceData, config);

        if (predictions && predictions.length > 0) {
          const insight = await this.generatePredictionInsight(predictions, sourceName, config);
          if (insight.confidence >= this.config.confidenceThreshold) {
            insights.push(insight);
          }
        }
      }

      logger.info('Predictions generated', {
        predictionsGenerated: insights.length,
        horizon: config.horizon
      });

      this.metrics.gauge('ai_insights.predictions.generated', insights.length);

      return insights.slice(0, this.config.maxInsightsPerRequest);

    } catch (error: unknown) {
      logger.error('Failed to generate predictions', { error });
      this.metrics.increment('ai_insights.predictions.failed');
      return [];
    }
  }

  /**
   * Find correlations between different metrics
   */
  async findCorrelations(
    data: Record<string, any[]>,
    config: CorrelationConfig
  ): Promise<AIGeneratedInsight[]> {
    try {
      logger.debug('Finding correlations', {
        method: config.method,
        threshold: config.threshold
      });

      const insights: AIGeneratedInsight[] = [];

      // Prepare correlation matrix
      const correlations = await this.calculateCorrelationMatrix(data, config);

      // Find significant correlations
      for (const correlation of correlations) {
        if (Math.abs(correlation.coefficient) >= config.threshold) {
          const insight = await this.generateCorrelationInsight(correlation, config);
          if (insight.confidence >= this.config.confidenceThreshold) {
            insights.push(insight);
          }
        }
      }

      // Sort by correlation strength
      insights.sort((a, b) => b.confidence - a.confidence);

      logger.info('Correlation analysis completed', {
        correlationsFound: insights.length,
        strongCorrelations: insights.filter(i => i.confidence > 0.8).length
      });

      this.metrics.gauge('ai_insights.correlations.found', insights.length);

      return insights.slice(0, this.config.maxInsightsPerRequest);

    } catch (error: unknown) {
      logger.error('Failed to find correlations', { error });
      this.metrics.increment('ai_insights.correlations.failed');
      return [];
    }
  }

  /**
   * Generate actionable recommendations
   */
  async generateRecommendations(
    data: Record<string, any[]>,
    kpis: Record<string, number>,
    config: RecommendationConfig
  ): Promise<AIGeneratedInsight[]> {
    try {
      logger.debug('Generating recommendations', {
        context: config.context,
        priority: config.priority
      });

      const insights: AIGeneratedInsight[] = [];

      // Analyze current performance
      const performanceAnalysis = await this.analyzePerformance(data, kpis, config);

      // Generate recommendations using LLM
      const recommendations = await this.generateLLMRecommendations(
        performanceAnalysis,
        config
      );

      for (const recommendation of recommendations) {
        const insight = await this.createRecommendationInsight(recommendation, config);
        if (insight.confidence >= this.config.confidenceThreshold) {
          insights.push(insight);
        }
      }

      // Sort by business impact
      insights.sort((a, b) => {
        const impactOrder = { critical: 4, high: 3, medium: 2, low: 1 };
        const aImpact = impactOrder[a.priority as keyof typeof impactOrder];
        const bImpact = impactOrder[b.priority as keyof typeof impactOrder];
        return bImpact - aImpact || b.confidence - a.confidence;
      });

      logger.info('Recommendations generated', {
        recommendationsGenerated: insights.length,
        highPriorityRecommendations: insights.filter(i => i.priority === 'high' || i.priority === 'critical').length
      });

      this.metrics.gauge('ai_insights.recommendations.generated', insights.length);

      return insights.slice(0, config.maxRecommendations || this.config.maxInsightsPerRequest);

    } catch (error: unknown) {
      logger.error('Failed to generate recommendations', { error });
      this.metrics.increment('ai_insights.recommendations.failed');
      return [];
    }
  }

  /**
   * Generate natural language explanations for insights
   */
  async generateNaturalLanguageExplanation(
    insight: Omit<AIGeneratedInsight, 'description' | 'details'>,
    context: Record<string, any>
  ): Promise<{ description: string; details: string }> {
    try {
      logger.debug('Generating natural language explanation', {
        insightType: insight.type,
        priority: insight.priority
      });

      const prompt = this.buildExplanationPrompt(insight, context);
      const explanation = await this.invokeLLMForExplanation(prompt);

      return {
        description: explanation.summary,
        details: explanation.detailed
      };

    } catch (error: unknown) {
      logger.error('Failed to generate natural language explanation', { error });
      return {
        description: `${insight.type} detected with ${(insight.confidence * 100).toFixed(1)}% confidence`,
        details: 'Detailed explanation not available'
      };
    }
  }

  // Private helper methods

  private async testModelConnections(): Promise<void> {
    try {
      // Test Bedrock connection
      if (this.config.bedrockModel) {
        await this.invokeLLMForExplanation('Test connection');
      }

      // Test SageMaker endpoints
      for (const [name, endpoint] of Object.entries(this.config.sagemakerEndpoints)) {
        if (endpoint) {
          await this.testSagemakerEndpoint(endpoint);
        }
      }

    } catch (error: unknown) {
      logger.warn('Some model connections failed during testing', { error });
    }
  }

  private async loadModelConfigurations(): Promise<void> {
    // Load pre-trained model configurations
    this.modelConfigs.set('anomaly_detection', {
      algorithm: 'isolation_forest',
      contamination: 0.1,
      nEstimators: 100
    });

    this.modelConfigs.set('time_series_forecasting', {
      algorithm: 'prophet',
      seasonality: 'auto',
      holidays: true
    });

    this.modelConfigs.set('correlation_analysis', {
      method: 'pearson',
      minSamples: 10,
      significanceLevel: 0.05
    });
  }

  private async performTrendAnalysis(data: any[] | undefined, sourceName: string): Promise<TrendAnalysis> {
    // Mock implementation - in production, this would use actual ML models
    const values = data?.map(d => d.value || d.count || 0) || [];
    const direction = values[values.length - 1] > values[0] ? 'up' : 'down';
    const strength = Math.abs(values[values.length - 1] - values[0]) / Math.max(values[0], 1);

    return {
      metric: sourceName,
      direction,
      strength,
      significance: 0.85,
      seasonality: {
        detected: false
      },
      changePoints: [],
      forecast: []
    };
  }

  private async generateTrendInsight(
    trendAnalysis: TrendAnalysis,
    sourceName: string
  ): Promise<AIGeneratedInsight> {
    const priority = trendAnalysis.strength > 0.5 ? 'high' : 'medium';
    const confidence = trendAnalysis.significance;

    return {
      id: uuidv4(),
      type: 'trend',
      priority: priority as any,
      confidence,
      title: `${trendAnalysis.direction === 'up' ? 'Increasing' : 'Decreasing'} Trend in ${sourceName}`,
      description: `Significant ${trendAnalysis.direction} trend detected`,
      details: `The metric shows a ${(trendAnalysis.strength * 100).toFixed(1)}% change with ${(confidence * 100).toFixed(1)}% confidence`,
      visualizations: [],
      actionItems: [],
      dataPoints: [],
      metadata: {
        algorithm: 'trend_analysis',
        modelVersion: '1.0.0',
        generatedAt: new Date(),
        reviewStatus: 'pending'
      }
    };
  }

  private async detectAnomaliesInDataset(
    data: any[] | undefined,
    config: AnomalyDetectionConfig
  ): Promise<AnomalyResult[]> {
    // Mock implementation - in production, this would use actual ML models
    const results: AnomalyResult[] = [];

    // Simple threshold-based anomaly detection for demonstration
    const values = data?.map(d => d.value || d.count || 0) || [];
    const mean = values.reduce((sum, v) => sum + v, 0) / values.length;
    const std = Math.sqrt(values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length);
    const threshold = config.sensitivity * std;

    data?.forEach((dataPoint, index) => {
      const value = dataPoint.value || dataPoint.count || 0;
      const deviation = Math.abs(value - mean);
      const isAnomaly = deviation > threshold;

      if (isAnomaly) {
        results.push({
          dataPoint,
          score: deviation / std,
          isAnomaly: true,
          severity: deviation > 3 * std ? 'critical' : deviation > 2 * std ? 'high' : 'medium',
          explanation: `Value ${value} deviates significantly from expected range`,
          similarPatterns: [],
          recommendedActions: ['Investigate cause', 'Verify data quality']
        });
      }
    });

    return results;
  }

  private async generateAnomalyInsight(
    anomaly: AnomalyResult,
    sourceName: string,
    config: AnomalyDetectionConfig
  ): Promise<AIGeneratedInsight> {
    return {
      id: uuidv4(),
      type: 'anomaly',
      priority: anomaly.severity as any,
      confidence: Math.min(anomaly.score / 3, 1),
      title: `Anomaly Detected in ${sourceName}`,
      description: anomaly.explanation,
      details: `Anomaly score: ${anomaly.score.toFixed(2)}, Severity: ${anomaly.severity}`,
      visualizations: [],
      actionItems: anomaly.recommendedActions.map(action => ({
        id: uuidv4(),
        title: action,
        description: action,
        priority: 'medium' as any,
        dueDate: new Date(Date.now() + 24 * 60 * 60 * 1000)
      })),
      dataPoints: [anomaly.dataPoint],
      metadata: {
        algorithm: config.algorithm,
        modelVersion: '1.0.0',
        generatedAt: new Date(),
        reviewStatus: 'pending'
      }
    };
  }

  private async generateTimeSeriesPredictions(
    data: any[] | undefined,
    config: PredictionConfig
  ): Promise<any[]> {
    // Mock implementation - in production, this would use actual forecasting models
    const lastValue = data?.[data.length - 1]?.value || 0;
    const predictions = [];

    for (let i = 1; i <= 30; i++) {
      predictions.push({
        date: new Date(Date.now() + i * 24 * 60 * 60 * 1000),
        value: lastValue * (1 + (Math.random() - 0.5) * 0.1),
        confidence_lower: lastValue * 0.9,
        confidence_upper: lastValue * 1.1
      });
    }

    return predictions;
  }

  private async generatePredictionInsight(
    predictions: any[] | undefined,
    sourceName: string,
    config: PredictionConfig
  ): Promise<AIGeneratedInsight> {
    const avgValue = predictions.reduce((sum, p) => sum + p.value, 0) / predictions.length;

    return {
      id: uuidv4(),
      type: 'prediction',
      priority: 'medium',
      confidence: config.confidence,
      title: `${config.horizon} Forecast for ${sourceName}`,
      description: `Predicted average value: ${avgValue.toFixed(2)}`,
      details: `Forecast generated for ${config.horizon} with ${(config.confidence * 100).toFixed(1)}% confidence`,
      visualizations: [],
      actionItems: [],
      dataPoints: predictions,
      metadata: {
        algorithm: config.algorithm || 'prophet',
        modelVersion: '1.0.0',
        generatedAt: new Date(),
        reviewStatus: 'pending'
      }
    };
  }

  private async calculateCorrelationMatrix(
    data: Record<string, any[]>,
    config: CorrelationConfig
  ): Promise<Array<{ var1: string; var2: string; coefficient: number; pValue: number }>> {
    // Mock implementation - in production, this would calculate actual correlations
    const correlations = [];
    const variables = Object.keys(data);

    for (let i = 0; i < variables.length; i++) {
      for (let j = i + 1; j < variables.length; j++) {
        correlations.push({
          var1: variables[i],
          var2: variables[j],
          coefficient: (Math.random() - 0.5) * 2, // Random correlation for demo
          pValue: Math.random() * 0.1
        });
      }
    }

    return correlations;
  }

  private async generateCorrelationInsight(
    correlation: { var1: string; var2: string; coefficient: number; pValue: number },
    config: CorrelationConfig
  ): Promise<AIGeneratedInsight> {
    const strength = Math.abs(correlation.coefficient);
    const direction = correlation.coefficient > 0 ? 'positive' : 'negative';

    return {
      id: uuidv4(),
      type: 'correlation',
      priority: strength > 0.8 ? 'high' : 'medium',
      confidence: strength,
      title: `${direction.charAt(0).toUpperCase() + direction.slice(1)} Correlation Found`,
      description: `${correlation.var1} and ${correlation.var2} show ${direction} correlation`,
      details: `Correlation coefficient: ${correlation.coefficient.toFixed(3)}, p-value: ${correlation.pValue.toFixed(3)}`,
      visualizations: [],
      actionItems: [],
      dataPoints: [],
      metadata: {
        algorithm: 'correlation_analysis',
        modelVersion: '1.0.0',
        generatedAt: new Date(),
        reviewStatus: 'pending'
      }
    };
  }

  private async analyzePerformance(
    data: Record<string, any[]>,
    kpis: Record<string, number>,
    config: RecommendationConfig
  ): Promise<any> {
    // Analyze current performance against benchmarks
    return {
      kpiPerformance: Object.entries(kpis).map(([kpi, value]) => ({
        kpi,
        value,
        benchmark: value * 1.1, // Mock benchmark
        performance: value / (value * 1.1)
      })),
      trends: Object.keys(data),
      opportunities: ['Improve efficiency', 'Reduce costs', 'Enhance quality']
    };
  }

  private async generateLLMRecommendations(
    performanceAnalysis: any,
    config: RecommendationConfig
  ): Promise<any[]> {
    // Mock recommendations - in production, this would use LLM
    return [
      {
        title: 'Optimize Resource Allocation',
        description: 'Reallocate resources based on demand patterns',
        impact: 'high',
        effort: 'medium',
        implementationSteps: [
          'Analyze current resource utilization',
          'Identify optimization opportunities',
          'Implement resource reallocation plan'
        ]
      }
    ];
  }

  private async createRecommendationInsight(
    recommendation: any,
    config: RecommendationConfig
  ): Promise<AIGeneratedInsight> {
    return {
      id: uuidv4(),
      type: 'recommendation',
      priority: recommendation.impact as any,
      confidence: 0.85,
      title: recommendation.title,
      description: recommendation.description,
      details: `Implementation effort: ${recommendation.effort}`,
      visualizations: [],
      actionItems: recommendation.implementationSteps?.map((step: string) => ({
        id: uuidv4(),
        title: step,
        description: step,
        priority: 'medium' as any
      })) || [],
      dataPoints: [],
      metadata: {
        algorithm: 'llm_recommendations',
        modelVersion: '1.0.0',
        generatedAt: new Date(),
        reviewStatus: 'pending'
      }
    };
  }

  private buildExplanationPrompt(
    insight: Omit<AIGeneratedInsight, 'description' | 'details'>,
    context: Record<string, any>
  ): string {
    return `
      Generate a clear, actionable explanation for the following ${insight.type} insight:

      Type: ${insight.type}
      Priority: ${insight.priority}
      Confidence: ${(insight.confidence * 100).toFixed(1)}%
      Title: ${insight.title}

      Context: ${JSON.stringify(context)}

      Please provide:
      1. A concise summary (2-3 sentences)
      2. A detailed explanation with actionable recommendations

      Focus on business impact and practical next steps.
    `;
  }

  private async invokeLLMForExplanation(prompt: string): Promise<{ summary: string; detailed: string }> {
    try {
      const command = new InvokeModelCommand({
        modelId: this.config.bedrockModel,
        contentType: 'application/json',
        accept: 'application/json',
        body: JSON.stringify({
          prompt,
          max_tokens: 500,
          temperature: 0.7
        })
      });

      const response = await this.bedrockClient.send(command);
      const responseBody = JSON.parse(new TextDecoder().decode(response.body));

      // Parse response based on model type
      const completion = responseBody.completion || responseBody.generated_text || '';

      return {
        summary: completion.split('\n')[0] || 'Summary not available',
        detailed: completion || 'Detailed explanation not available'
      };

    } catch (error: unknown) {
      logger.error('Failed to invoke LLM for explanation', { error });
      return {
        summary: 'AI explanation not available',
        detailed: 'Unable to generate detailed explanation'
      };
    }
  }

  private async testSagemakerEndpoint(endpoint: string): Promise<void> {
    try {
      const command = new InvokeEndpointCommand({
        EndpointName: endpoint,
        ContentType: 'application/json',
        Body: JSON.stringify({ test: 'connection' })
      });

      await this.sagemakerClient.send(command);
    } catch (error: unknown) {
      logger.warn(`SageMaker endpoint ${endpoint} test failed`, { error });
    }
  }

  /**
   * Get service health status
   */
  async getHealthStatus(): Promise<{
    status: 'healthy' | 'degraded' | 'unhealthy';
    initialized: boolean;
    bedrockConnected: boolean;
    sagemakerConnected: boolean;
    cacheSize: number;
    modelsLoaded: number;
  }> {
    const cacheSize = this.insightCache.size;
    const modelsLoaded = this.modelConfigs.size;
    
    // Test connections
    let bedrockConnected = false;
    let sagemakerConnected = false;
    
    try {
      // Test Bedrock connection
      const testCommand = new InvokeModelCommand({
        modelId: this.config.bedrockModel,
        contentType: 'application/json',
        accept: 'application/json',
        body: JSON.stringify({
          prompt: 'test',
          max_tokens: 1
        })
      });
      await this.bedrockClient.send(testCommand);
      bedrockConnected = true;
    } catch (error: unknown) {
      logger.warn('Bedrock health check failed', { error: (error instanceof Error ? error.message : String(error)) });
    }
    
    try {
      // Test SageMaker endpoints
      for (const endpoint of Object.values(this.config.sagemakerEndpoints)) {
        if (endpoint) {
          await this.testSagemakerEndpoint(endpoint);
          sagemakerConnected = true;
          break;
        }
      }
    } catch (error: unknown) {
      logger.warn('SageMaker health check failed', { error: (error instanceof Error ? error.message : String(error)) });
    }
    
    let status: 'healthy' | 'degraded' | 'unhealthy' = 'healthy';
    
    if (!this.isInitialized) {
      status = 'unhealthy';
    } else if (!bedrockConnected && !sagemakerConnected) {
      status = 'unhealthy';
    } else if (!bedrockConnected || !sagemakerConnected) {
      status = 'degraded';
    }
    
    return {
      status,
      initialized: this.isInitialized,
      bedrockConnected,
      sagemakerConnected,
      cacheSize,
      modelsLoaded
    };
  }

  private setupEventHandlers(): void {
    this.on('initialized', () => {
      this.metrics.increment('ai_insights.initialized');
    });

    this.on('insight:generated', (insight: AIGeneratedInsight) => {
      this.metrics.increment(`ai_insights.${insight.type}.generated`);
      this.metrics.gauge(`ai_insights.confidence.${insight.type}`, insight.confidence);
    });

    this.on('error', (error) => {
      logger.error('AI Insights Engine error', { error });
      this.metrics.increment('ai_insights.errors');
    });
  }
}

// Additional interfaces
interface VisualizationConfig {
  type: 'line' | 'bar' | 'pie' | 'area' | 'scatter' | 'heatmap' | 'gauge' | 'treemap';
  dimensions: string[];
  metrics: string[];
  colors: string[];
  animations: boolean;
  interactions: boolean;
  responsive: boolean;
}

interface ActionItem {
  id: string;
  title: string;
  description: string;
  priority: 'low' | 'medium' | 'high';
  dueDate?: Date;
}

